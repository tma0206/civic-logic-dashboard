import streamlit as st
import pandas as pd
import altair as alt
import sys
import os
import json

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from ingestion.api_client import fetch_diet_records
from ingestion.estat_client import fetch_stats_for_keyword
from analysis.classifier import CLODClassifier
from analysis.insight_generator import generate_insight

st.set_page_config(page_title="C-LOD ãƒªã‚¢ãƒ«åˆ†æ", layout="wide", page_icon="ğŸ›ï¸")

@st.cache_data
def load_starter_pack():
    path = os.path.join(os.path.dirname(__file__), '..', 'data', 'starter_pack.json')
    if os.path.exists(path):
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}

def render_depth_gauge(score_text):
    if "Level 4" in score_text:
        pct, color = 100, "#28a745" # Green
    elif "Level 3" in score_text:
        pct, color = 75, "#007bff"  # Blue
    elif "Level 2" in score_text:
        pct, color = 50, "#ffc107"  # Yellow
    else:
        pct, color = 25, "#dc3545"  # Red
        
    html = f"""
    <div style="width: 100%; background-color: #333; border-radius: 5px; margin-bottom: 10px;">
      <div style="width: {pct}%; height: 24px; background-color: {color}; border-radius: 5px; text-align: center; color: { 'white' if pct != 50 else 'black' }; font-weight: bold; line-height: 24px;">
        {score_text}
      </div>
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)

def main():
    st.warning("**Current Version:** 1.1 Precision Update ğŸš€")
    st.title("ğŸ›ï¸ C-LOD: Policy vs. Reality (Gap Analysis) ğŸ‡¯ğŸ‡µ")
    st.markdown("æ”¿æ²»å®¶ã®ç™ºè¨€ï¼ˆWordsï¼‰ã¨ç¾å®Ÿã®çµ±è¨ˆï¼ˆResultsï¼‰ã®ã‚®ãƒ£ãƒƒãƒ—ã‚’å³åº§ã«å¯è¦–åŒ–ã—ã€ç™ºè¨€ã®ã€Œè«–ç†çš„æ·±åº¦ã€ã‚’è©•ä¾¡ã—ã¾ã™ã€‚")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã¨æ¤œç´¢è¨­å®š
    st.sidebar.header("âš™ï¸ Data Source")
    data_mode = st.sidebar.radio("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’é¸æŠ", ["Starter Pack (Demo)", "Live API Search (å›½ä¼šå›³æ›¸é¤¨)"])
    
    starter_data = load_starter_pack()
    
    keyword = "å°‘å­åŒ–"
    raw_records = []
    
    if data_mode == "Starter Pack (Demo)":
        st.sidebar.info("ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ï¼šä¿å­˜æ¸ˆã¿ã®ãƒ‡ãƒ¼ã‚¿ã‚’é«˜é€Ÿè¡¨ç¤ºã—ã¾ã™ï¼ˆAPIã‚­ãƒ¼ä¸è¦ï¼‰ã€‚")
        if starter_data:
            keyword = st.sidebar.selectbox("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", list(starter_data.keys()))
            raw_records = starter_data[keyword]
        else:
            st.sidebar.error("Starter PackãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    else:
        st.sidebar.warning("ãƒ©ã‚¤ãƒ–ãƒ¢ãƒ¼ãƒ‰ï¼šãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§å›½ä¼šAPIã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¾ã™ã€‚")
        keyword = st.sidebar.text_input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", value="å°‘å­åŒ–")
        limit = st.sidebar.slider("å–å¾—ä»¶æ•°", min_value=1, max_value=30, value=5)
        
        if st.sidebar.button("ğŸ” ãƒ©ã‚¤ãƒ–æ¤œç´¢å®Ÿè¡Œ", type="primary"):
            st.cache_data.clear()
            with st.spinner(f"ã€Œ{keyword}ã€ã«é–¢ã™ã‚‹å›½ä¼šç™ºè¨€ã‚’å–å¾—ä¸­... â³"):
                try:
                    raw_records = fetch_diet_records(keyword=keyword, max_records=limit)
                    st.session_state['live_records'] = raw_records
                    st.success(f"ğŸ“º ãƒ‡ãƒãƒƒã‚°: `{keyword}` ã®ãƒ‡ãƒ¼ã‚¿ã‚’ {len(raw_records)} ä»¶å–å¾—ã—ã¾ã—ãŸï¼")
                except Exception as e:
                    st.error(f"å›½ä¼šä¼šè­°éŒ²APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
                    
        # Button pressed logic memory
        if 'live_records' in st.session_state:
            raw_records = st.session_state['live_records']

    if not raw_records and data_mode == "Live API Search (å›½ä¼šå›³æ›¸é¤¨)":
        st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€Œãƒ©ã‚¤ãƒ–æ¤œç´¢å®Ÿè¡Œã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ãã ã•ã„ã€‚")
        return
    elif not raw_records:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # Metadata-First Search UI
    st.subheader(f"ğŸ—£ï¸ ã€Œ{keyword}ã€ã«é–¢ã™ã‚‹å›½ä¼šç™ºè¨€ãƒªã‚¹ãƒˆ")
    
    # Extract metadata for the table (excluding full voice text to keep it snappy)
    meta_df = pd.DataFrame(raw_records)[["date", "speaker", "meeting"]]
    meta_df.index = meta_df.index + 1 # 1-indexed for display
    
    st.dataframe(
        meta_df,
        column_config={
            "date": "ç™ºè¨€æ—¥",
            "speaker": "ç™ºè¨€è€…",
            "meeting": "ä¼šè­°å"
        },
        width="stretch"
    )
    
    # é¸æŠã—ãŸç™ºè¨€ã®åˆ†æ (Detailed Analysis)
    st.subheader("ğŸ§  Deep Analysis (è«–ç†çš„æ·±åº¦ã®è©•ä¾¡)")
    st.markdown("ãƒªã‚¹ãƒˆã‹ã‚‰ç™ºè¨€ã‚’é¸ã‚“ã§ã€è©³ç´°ãªåˆ†æã¨ç¾å®Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆe-Statï¼‰ã¨ã®æ¯”è¼ƒã‚’è¡Œã„ã¾ã™ã€‚")
    
    record_options = [f"[{r['date']}] {r['speaker']} ({r['meeting']})" for r in raw_records]
    selected_idx = st.selectbox("åˆ†æå¯¾è±¡ã®ç™ºè¨€ã‚’é¸æŠ:", range(len(record_options)), format_func=lambda x: record_options[x])
    
    selected_record = raw_records[selected_idx]
    speech_year = selected_record['date'].split('-')[0] # Get the year for causality plot
    
    # é…å»¶è©•ä¾¡ï¼šé¸æŠã•ã‚ŒãŸæ™‚ã®ã¿ L1-L4 åˆ†æã‚’å®Ÿè¡Œ
    classifier = CLODClassifier()
    analyzed_record = classifier.predict(selected_record.copy())
    
    col_analysis, col_chart = st.columns([1, 1])
    
    with col_analysis:
        st.markdown("#### ç™ºè¨€å†…å®¹ (Words)")
        st.info(f"ã€Œ... {analyzed_record['voice'][:300]} ...ã€") # æŠœç²‹è¡¨ç¤º
        
        # Evidence Badge
        if analyzed_record.get('Has_Evidence', False):
            st.markdown("### ğŸ… Evidence Badge\n**[âœ… Evidence Present]** å…·ä½“çš„ãªæ•°å€¤ãƒ»ãƒ‡ãƒ¼ã‚¿ã¸ã®è¨€åŠãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚")
        else:
            st.markdown("### ğŸ… Evidence Badge\n**[âŒ No Evidence]** ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãå®¢è¦³çš„ãªè£ä»˜ã‘ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")
        
        st.markdown("#### è«–ç†çš„æ·±åº¦ (Logical Depth L1-L4)")
        render_depth_gauge(analyzed_record['L4_Final_Status'])
        
        st.markdown(f"**L2 (ã‚³ãƒŸãƒƒãƒˆãƒ¡ãƒ³ãƒˆ):** {analyzed_record['L2_Urgency']}")
        if "Level 4" in analyzed_record['L4_Final_Status']:
            st.success("âœ… **é«˜è©•ä¾¡**: å…·ä½“çš„ãªãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸå®Ÿç¾æ€§ã®é«˜ã„å…¬ç´„ã§ã™ã€‚")
        elif "Level 1" in analyzed_record['L4_Final_Status']:
            st.error("ğŸ“‰ **æŠ½è±¡çš„**: å…·ä½“æ€§ãŒæ¬ ã‘ã¦ãŠã‚Šã€ãƒãƒ”ãƒ¥ãƒªã‚ºãƒ ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

    with col_chart:
        st.markdown("#### ç¾å®Ÿã®çµ±è¨ˆæ¨ç§» (Results - e-Stat)")
        
        with st.spinner("e-Statãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­... â³"):
            stats_info = fetch_stats_for_keyword(keyword)
            
        st.markdown(f"**âš¡ Causality Summary**\n- **Speech Topic:** `{keyword}`\n- **Statistic:** `{stats_info['title']}`")
        
        df_stats = pd.DataFrame(stats_info['data'])
        
        # Causality Visualization: Overlay the speech year on the reality chart
        base_chart = alt.Chart(df_stats).mark_line(point=True).encode(
            x=alt.X("year:O", title="å¹´"),
            y=alt.Y("value:Q", title=stats_info['y_label'], scale=alt.Scale(zero=False)),
            tooltip=["year", "value"]
        ).properties( height=250 )
        
        # Highlight the year the speech was made
        try:
            speech_year_int = int(speech_year)
            # Find if speech year is in our stats data
            if str(speech_year) in df_stats['year'].values:
                highlight = alt.Chart(pd.DataFrame({'year': [str(speech_year)]})).mark_rule(color='red', strokeWidth=2).encode(
                    x='year:O'
                )
                final_chart = base_chart + highlight
                st.altair_chart(final_chart, width="stretch")
                st.caption(f"ğŸ”´ èµ¤ç·š: ç™ºè¨€ãŒè¡Œã‚ã‚ŒãŸå¹´ ({speech_year}å¹´)")
            else:
                st.altair_chart(base_chart, width="stretch")
                st.caption(f"ï¼ˆâ€»ç™ºè¨€å¹´ã®{speech_year}å¹´ã¯ã‚°ãƒ©ãƒ•è¡¨ç¤ºç¯„å›²å¤–ã§ã™ï¼‰")
        except:
            st.altair_chart(base_chart, width="stretch")

    st.markdown("---")
    st.subheader("ğŸ¤– AIã®ã‚„ã•ã—ã„è¦ç´„ (Gemini Insight)")
    with st.spinner("GeminiãŒç™ºè¨€ã¨ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è§£ã„ã¦ã„ã¾ã™... âœ¨"):
        # We use the full text from analyzed_record['voice'] and the stats title
        insight_text = generate_insight(analyzed_record.get('voice', ''), keyword, stats_info.get('title', 'é–¢é€£çµ±è¨ˆ'))
        st.info(insight_text, icon="ğŸ’¡")

if __name__ == "__main__":
    main()
